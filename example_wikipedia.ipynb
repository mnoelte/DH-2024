{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d183a-44df-4f33-8be6-3b817892b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa073e-c8b6-49de-93e4-19822a7a8ca3",
   "metadata": {},
   "source": [
    "# prepare script; read web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb94e0-0a5f-41f7-b4b5-9476a2c0eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\") \n",
    "#the string \"html.parser\", tells the object which parser to use behind the scenes. \"html.parser\" represents Pythonâ€™s built-in HTML parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33fd35-4187-424f-b1d6-4e8bf6034961",
   "metadata": {},
   "source": [
    "### soup.select(\"h2\")  and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1a054-5f07-4c2a-be85-55c736ab69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "elements = soup.select(\"h2\")\n",
    "for element in elements:\n",
    "    data.append(element.get_text(strip=True))\n",
    "\n",
    "# Print the scraped data\n",
    "for item in data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e3476-c32e-410e-8810-aa199d8ce771",
   "metadata": {},
   "source": [
    "### ... soup.find_all(\"h2\")  gives the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07226083",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "elements = soup.find_all(\"h2\")\n",
    "for element in elements:\n",
    "    data.append(element.get_text(strip=True))\n",
    "\n",
    "# Print the scraped data\n",
    "for item in data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ae2d9-1ee4-4001-bd6f-eb9e139c94c6",
   "metadata": {},
   "source": [
    "### The next cell is far from beeing perfect :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# Find all h2 tags on the page\n",
    "h2_tags = soup.find_all('h2')\n",
    "\n",
    "# Dictionary to store the h2 text and the paragraphs following each h2\n",
    "h2_paragraphs = {}\n",
    "h2_u_lists = {}\n",
    "\n",
    "# Loop through each h2 tag\n",
    "for h2 in h2_tags:\n",
    "    # Find the next <p> tag after each <h2>, regardless of its position\n",
    "    next_paragraph = h2.find_next('p')\n",
    "    next_u_list = h2.find_next('ul')\n",
    "    \n",
    "    # If a paragraph was found, get its text\n",
    "    if next_paragraph:\n",
    "        h2_paragraphs[h2.get_text()] = next_paragraph.get_text()\n",
    "\n",
    "    # If an u_list was found, get its text\n",
    "    if next_u_list:\n",
    "        h2_u_lists[h2.get_text()] = next_u_list.get_text()\n",
    "\n",
    "# Print out the results\n",
    "print('------------------- Headlines and paragraphs ----------------')\n",
    "for h2, paragraph in h2_paragraphs.items():\n",
    "    print(f\"Headline: {h2}\")\n",
    "    print(f\"Paragraph: {paragraph}\\n\")\n",
    "print('------------------- Headlines and lists ----------------')\n",
    "# Print out the results\n",
    "for h2, u_list in h2_u_lists.items():\n",
    "    print(f\"Headline: {h2}\")\n",
    "    print(f\"List: {u_list}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769b8bc-01ec-4752-82cc-9b80347aa36f",
   "metadata": {},
   "source": [
    "### In this case 'wikipedia main page' h2.find_next(['p', 'ul']) does what I want :\n",
    "What has happened to?  :\n",
    "```\n",
    "Headline: On this day\n",
    "Paragraph: October 26\n",
    "```\n",
    "Please explain !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038bdf4a-daa7-4854-8eca-7260341387f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all h2 tags on the page\n",
    "h2_tags = soup.find_all('h2')\n",
    "\n",
    "# Dictionary to store the h2 text and the paragraphs or lists following each h2\n",
    "h2_content = {}\n",
    "\n",
    "# Loop through each h2 tag\n",
    "for h2 in h2_tags:\n",
    "    # Find the next <p> or <ul> tag after each <h2>, regardless of its position\n",
    "    next_tag = h2.find_next(['p', 'ul'])\n",
    "    \n",
    "    # If a tag was found, get its text or content\n",
    "    if next_tag:\n",
    "        # Store the content based on the tag type\n",
    "        if next_tag.name == 'p':\n",
    "            h2_content[h2.get_text()] = next_tag.get_text()\n",
    "        elif next_tag.name == 'ul':\n",
    "            # For <ul>, get a list of all <li> texts\n",
    "            h2_content[h2.get_text()] = [li.get_text() for li in next_tag.find_all('li')]\n",
    "\n",
    "# Print out the results\n",
    "for h2, content in h2_content.items():\n",
    "    print(f\"Headline: {h2}\")\n",
    "    if isinstance(content, list):\n",
    "        print(\"List items:\")\n",
    "        for item in content:\n",
    "            print(f\" - {item}\")\n",
    "    else:\n",
    "        print(f\"Paragraph: {content}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
